{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Langchain Chains\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "load_dotenv()\n",
                "\n",
                "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
                "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Chain 1\n",
                "\n",
                "A basic LangChain setup where a prompt template is used with a language model to generate a joke based on a given topic.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "AIMessage(content='Why did the apple go to school? Because it wanted to be a smart apple!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 13, 'total_tokens': 31, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-09230feb-3e59-4a0d-b205-d53399426824-0', usage_metadata={'input_tokens': 13, 'output_tokens': 18, 'total_tokens': 31, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
                        ]
                    },
                    "execution_count": 1,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from langchain_openai import ChatOpenAI\n",
                "from langchain_core.prompts import PromptTemplate\n",
                "\n",
                "\n",
                "llm = ChatOpenAI(model=\"gpt-4-turbo\")\n",
                "prompt = PromptTemplate.from_template(\"Tell me a joke about {topic}\")\n",
                "\n",
                "chain = prompt | llm\n",
                "chain.invoke({\"topic\": \"Apple\"})"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Chain 2\n",
                "\n",
                "A LangChain setup with a chat-based prompt that guides the model to provide a solution for a given topic.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "AIMessage(content='Certainly! Here is a langchain chain for a simple Leetcode problem of finding the sum of two numbers:\\n\\n1. Define two variables `num1` and `num2` to store the two input numbers.\\n2. Prompt the user to enter the first number `num1`.\\n3. Prompt the user to enter the second number `num2`.\\n4. Calculate the sum of the two numbers and store it in a variable `sum`.\\n5. Display the sum of the two numbers to the user.\\n\\nThis langchain chain provides a step-by-step approach to solving the problem of finding the sum of two numbers. You can implement this chain in any programming language of your choice.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 138, 'prompt_tokens': 27, 'total_tokens': 165, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-55f03304-2370-459b-9ad9-9c0a10bcdb47-0', usage_metadata={'input_tokens': 27, 'output_tokens': 138, 'total_tokens': 165, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from langchain_openai import ChatOpenAI\n",
                "from langchain_core.prompts import ChatPromptTemplate\n",
                "\n",
                "\n",
                "llm = ChatOpenAI(model=\"gpt-4-turbo\")\n",
                "prompt = ChatPromptTemplate.from_messages(\n",
                "    [\n",
                "        (\"system\", \"You are langchain expert\"),\n",
                "        (\"human\", \"Help me write a langchain chain for {topic}\"),\n",
                "    ]\n",
                ")\n",
                "\n",
                "\n",
                "chain = prompt | llm\n",
                "chain.invoke({\"topic\": \"Leetcode problem\"})"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Chain 3\n",
                "\n",
                "A LangChain setup that uses a chat-based prompt alongside a RunnablePassthrough to pass the output of the model directly for further processing or chaining.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "{'prompt': ChatPromptValue(messages=[SystemMessage(content='You are langchain expert', additional_kwargs={}, response_metadata={}), HumanMessage(content='Help me write a langchain chain for Leetcode problem', additional_kwargs={}, response_metadata={})])}"
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from langchain_core.prompts import ChatPromptTemplate\n",
                "from langchain_core.runnables import RunnablePassthrough\n",
                "\n",
                "\n",
                "prompt = ChatPromptTemplate.from_messages(\n",
                "    [\n",
                "        (\"system\", \"You are langchain expert\"),\n",
                "        (\"human\", \"Help me write a langchain chain for {topic}\"),\n",
                "    ]\n",
                ")\n",
                "\n",
                "chain = prompt | {\"prompt\": RunnablePassthrough()}\n",
                "chain.invoke({\"topic\": \"Leetcode problem\"})"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Chain 4\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "'Coding, also known as programming, is the process of creating instructions for a computer to follow in order to perform a specific task. It is the language that computers understand and use to execute tasks and functions.\\n\\nLearning how to code can greatly benefit individuals in this digital age, as it opens up a world of opportunities in various industries such as software development, web design, data analysis, and more. It also helps to improve problem-solving skills, logic, and creativity.\\n\\nHere are 5 resources to help you get started with coding:\\n\\n1. Codecademy - A popular online platform that offers interactive coding tutorials in various languages such as HTML, CSS, JavaScript, Python, and more. It is ideal for beginners looking to learn the basics of coding.\\n\\n2. Khan Academy - A non-profit educational organization that provides free coding courses on computer programming, algorithms, and data structures. It is suitable for individuals of all ages and skill levels.\\n\\n3. FreeCodeCamp - An open-source community that offers coding challenges, projects, and certifications on topics such as Responsive Web Design, JavaScript Algorithms and Data Structures, Front End Libraries, and more.\\n\\n4. Coursera - An online learning platform that partners with universities and organizations to offer coding courses and specializations in topics like machine learning, artificial intelligence, and programming languages.\\n\\n5. LeetCode - A platform dedicated to preparing individuals for technical coding interviews through a vast collection of coding problems, mock interviews, and company-specific challenges. It is ideal for individuals looking to advance their coding skills and land jobs in the tech industry.'"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from langchain_core.prompts import ChatPromptTemplate\n",
                "from langchain_core.output_parsers import StrOutputParser\n",
                "from langchain_openai import ChatOpenAI\n",
                "from langchain_core.runnables import RunnablePassthrough\n",
                "\n",
                "\n",
                "prompt = ChatPromptTemplate.from_template(\n",
                "    \"Tell me about {topic} and share the resources as well, give me {resource_count}\"\n",
                ")\n",
                "llm = ChatOpenAI(model=\"gpt-4-turbo\")\n",
                "\n",
                "chain = prompt | llm | StrOutputParser()\n",
                "chain.invoke({\"topic\": \"Coding\", \"resource_count\": 5})"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Chain 5\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/yashjain/Developer/code/langchain-rag-learn/langchain-guide/.langchain-guide-env/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1375: UserWarning: Cannot use method='json_schema' with model gpt-4-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
                        "  warnings.warn(\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "(MobileReview(phone_model='iPhone 16 Pro Max', rating=4.5, pros=['Excellent display quality with high brightness levels', 'Improved battery life for extended usage', 'High-quality camera system with advanced processing', 'Enhanced audio capabilities for video production'], cons=['Incremental upgrade compared to previous models'], summary='The iPhone 16 Pro Max excels in display quality, battery efficiency, and camera performance, making it a top choice for users looking for a premium smartphone experience.'),\n",
                            " 'iPhone 16 Pro Max',\n",
                            " 4.5,\n",
                            " ['Excellent display quality with high brightness levels',\n",
                            "  'Improved battery life for extended usage',\n",
                            "  'High-quality camera system with advanced processing',\n",
                            "  'Enhanced audio capabilities for video production'],\n",
                            " ['Incremental upgrade compared to previous models'],\n",
                            " 'The iPhone 16 Pro Max excels in display quality, battery efficiency, and camera performance, making it a top choice for users looking for a premium smartphone experience.')"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from typing import List\n",
                "from langchain_openai import ChatOpenAI\n",
                "from pydantic import BaseModel, Field\n",
                "\n",
                "\n",
                "class MobileReview(BaseModel):\n",
                "    phone_model: str = Field(description=\"Name and model of the phone\")\n",
                "    rating: float = Field(description=\"Overall rating out of 5\")\n",
                "    pros: List[str] = Field(description=\"List of positive aspects\")\n",
                "    cons: List[str] = Field(description=\"List of negative aspects\")\n",
                "    summary: str = Field(description=\"Bried summary of the review\")\n",
                "\n",
                "\n",
                "review_text: str = \"\"\"\n",
                "    Overview of the iPhone 16 Pro Max\n",
                "        The iPhone 16 Pro Max, launched in September 2024, represents Apple's latest flagship smartphone, featuring significant enhancements in display technology, camera capabilities, and overall performance.\n",
                "    Key Specifications\n",
                "        Design and Build:\n",
                "            Finish Options: Black Titanium, White Titanium, Natural Titanium, Desert Titanium.\n",
                "            Dimensions:\n",
                "                Width: 77.6 mm (3.06 inches)\n",
                "                Height: 163 mm (6.42 inches)\n",
                "                Depth: 8.25 mm (0.32 inches)\n",
                "                Weight: 227 grams (7.99 ounces).\n",
                "            Material: Titanium frame with a Ceramic Shield front and textured matte glass back.\n",
                "        Display:\n",
                "            Type: Super Retina XDR OLED.\n",
                "            Size: 6.9 inches (diagonal).\n",
                "            Resolution: 2868 x 1320 pixels at 460 ppi.\n",
                "            Features:\n",
                "                Dynamic Island and Always-On display.\n",
                "                ProMotion technology with adaptive refresh rates from 1 Hz to 120 Hz.\n",
                "                Peak brightness of up to 2,000 nits for outdoor visibility.\n",
                "        Performance:\n",
                "            Chipset: A18 Pro chip.\n",
                "            RAM: 8 GB.\n",
                "            Battery: Improved battery life with a capacity of 4685 mAh, offering over 18 hours of usage on typical conditions157.\n",
                "        Camera System:\n",
                "            Rear Camera: Triple-lens system with a primary sensor featuring a ƒ/1.9 aperture, enhanced by Photonic Engine and Smart HDR5 for superior image processing.\n",
                "            Front Camera: High-resolution sensor capable of capturing detailed selfies even in low light conditions.\n",
                "        Storage Options:\n",
                "            Available capacities include 256GB, 512GB, and 1TB.\n",
                "    Notable Features\n",
                "        Camera Control Button: A new hardware feature allows quick access to the camera app and instant photo or video capture by pressing the button located below the power button25.\n",
                "        Software Enhancements: Ships with iOS 18, introducing more customization options for app icons on the home screen and improved user interface features2.\n",
                "        Audio Capabilities: Supports Spatial Audio recording and includes a four-microphone array for high-quality sound capture, making it suitable for video production24.\n",
                "    Performance Insights\n",
                "        Reviewers have noted that while the iPhone 16 Pro Max is an incremental upgrade compared to its predecessor, it excels in display quality and battery efficiency. The screen is praised for its color accuracy and brightness levels, making it one of the best smartphone displays available25. Additionally, the improved battery life has been highlighted as a significant advantage over previous models5.\n",
                "        In summary, the iPhone 16 Pro Max combines advanced technology with user-friendly features, making it a compelling choice for those seeking a premium smartphone experience.\n",
                "\"\"\"\n",
                "\n",
                "llm = ChatOpenAI(model=\"gpt-4-turbo\")\n",
                "structured_llm = llm.with_structured_output(MobileReview)\n",
                "output: MobileReview = structured_llm.invoke(review_text)\n",
                "\n",
                "output, output.phone_model, output.rating, output.pros, output.cons, output.summary"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Chain 6\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/yashjain/Developer/code/langchain-rag-learn/langchain-guide/.langchain-guide-env/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:1375: UserWarning: Cannot use method='json_schema' with model gpt-4-turbo since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
                        "  warnings.warn(\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "(Joke(joke='Why do programmers prefer dark mode? Because the light attracts bugs!', explaination='This joke plays on the common stereotype that programmers spend a lot of time debugging their code. Dark mode is also a popular feature in coding environments.', rating=4.5),\n",
                            " 'Why do programmers prefer dark mode? Because the light attracts bugs!',\n",
                            " 'This joke plays on the common stereotype that programmers spend a lot of time debugging their code. Dark mode is also a popular feature in coding environments.',\n",
                            " 4.5)"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from langchain_core.prompts import ChatPromptTemplate\n",
                "from langchain_openai import ChatOpenAI\n",
                "from pydantic import BaseModel, Field\n",
                "\n",
                "\n",
                "class Joke(BaseModel):\n",
                "    joke: str = Field(description=\"Joke itself\")\n",
                "    explaination: str = Field(description=\"How is this funny?\")\n",
                "    rating: float = Field(description=\"Overall rating out of 5\")\n",
                "\n",
                "\n",
                "llm = ChatOpenAI(model=\"gpt-4-turbo\")\n",
                "structured_llm = llm.with_structured_output(Joke)\n",
                "prompt = ChatPromptTemplate.from_template(\"Tell me a short joke about {topic}\")\n",
                "\n",
                "chain = prompt | structured_llm\n",
                "output: Joke = chain.invoke({\"topic\": \"Coding\"})\n",
                "\n",
                "output, output.joke, output.explaination, output.rating"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "text=\"Tell me a joke about {'topic': 'Apple', 'question': 'hello'} {'topic': 'Apple', 'question': 'hello'}\"\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "AIMessage(content=\"Why did the iPhone go to therapy? \\n\\nIt couldn't deal with Siri's attitude and was trying to find its core purpose!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 36, 'total_tokens': 63, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4-turbo-2024-04-09', 'system_fingerprint': 'fp_bf9cb2c77f', 'finish_reason': 'stop', 'logprobs': None}, id='run-35730937-873b-4f54-b291-db814803eab0-0', usage_metadata={'input_tokens': 36, 'output_tokens': 27, 'total_tokens': 63, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
                        ]
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from langchain_openai import ChatOpenAI\n",
                "from langchain_core.prompts import PromptTemplate\n",
                "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
                "\n",
                "\n",
                "llm = ChatOpenAI(model=\"gpt-4-turbo\")\n",
                "prompt = PromptTemplate.from_template(\"Tell me a joke about {topic} {question}\")\n",
                "\n",
                "def print_prompt(prompt):\n",
                "    print(prompt)\n",
                "    return prompt\n",
                "\n",
                "chain = {\"topic\": RunnablePassthrough(), \"question\": RunnablePassthrough()} | prompt | print_prompt | llm\n",
                "chain.invoke({\"topic\": \"Apple\", \"question\": \"hello\"})"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
